{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K - Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "features = iris.data\n",
    "label = iris.target\n",
    "dt_clf = DecisionTreeClassifier(random_state = 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 셋 크기 : 150\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits = 5)\n",
    "#데이터를 5개의 fold로 나누어라\n",
    "cv_accuracy = []\n",
    "#새로운 accuracy가 계속 누적되어지는 리스트 \n",
    "print('데이터 셋 크기 :', features.shape[0])\n",
    "#150개의 꽃에 대한 세부적인 데이터가 존재하며 이러한 데이터를 통해 4개의 꽃으로 분류 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#1 교차검증 정확도 : 1.0, 학습데이터 크기 : 120, 검증데이터 크기 : 30\n",
      "#1 검증 세트 인덱스 : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n",
      "\n",
      "#2 교차검증 정확도 : 0.9667, 학습데이터 크기 : 120, 검증데이터 크기 : 30\n",
      "#2 검증 세트 인덱스 : [30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
      " 54 55 56 57 58 59]\n",
      "\n",
      "#3 교차검증 정확도 : 0.8667, 학습데이터 크기 : 120, 검증데이터 크기 : 30\n",
      "#3 검증 세트 인덱스 : [60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83\n",
      " 84 85 86 87 88 89]\n",
      "\n",
      "#4 교차검증 정확도 : 0.9333, 학습데이터 크기 : 120, 검증데이터 크기 : 30\n",
      "#4 검증 세트 인덱스 : [ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
      "\n",
      "#5 교차검증 정확도 : 0.8333, 학습데이터 크기 : 120, 검증데이터 크기 : 30\n",
      "#5 검증 세트 인덱스 : [120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "\n",
      "## 평균 검증 정확도 :  0.9199999999999999\n"
     ]
    }
   ],
   "source": [
    "n_iter = 0\n",
    "#반복변수가 없기때문에 하나 지정 \n",
    "#KFold객체의 split() 호출하면 폴드별 학습용 , 검증용 ,테스트의 로우 인덱스를 array로 반환 \n",
    "for train_index, test_index in kfold.split(features):\n",
    "    #kfold를 사용할때에는 반복문을 사용하는데 아주 좋음\n",
    "    #iris데이터에서 나눈것을 train과 test_index를 넣어준다\n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    #각각 지정 \n",
    "    y_train, y_test = label[train_index], label[test_index]\n",
    "    #학습, 예측 \n",
    "    dt_clf.fit(X_train, y_train)\n",
    "    #train으로 의사결정나무 분류기에 학습 \n",
    "    pred = dt_clf.predict(X_test)\n",
    "    #test데이터를 통해 예측값 도출 \n",
    "    n_iter += 1\n",
    "    #한번씩 반복될때마다 1씩 추가 \n",
    "    #반복 시 마다 정확도 측정 \n",
    "    accuracy = np.round(accuracy_score(y_test,pred),4)\n",
    "    train_size = X_train.shape[0]\n",
    "    test_size = X_test.shape[0]\n",
    "    print('\\n#{0} 교차검증 정확도 : {1}, 학습데이터 크기 : {2}, 검증데이터 크기 : {3}'.format(n_iter, accuracy, train_size, test_size))\n",
    "    #위와 같은 방법으로 다양한 결과데이터들을 한번에 출력이 가능 \n",
    "    print('#{0} 검증 세트 인덱스 : {1}'.format(n_iter, test_index))\n",
    "    cv_accuracy.append(accuracy)\n",
    "    \n",
    "#개별 iteration별 정확도를 합하여 평균을 계산하고 정확도를 도출 \n",
    "print('\\n## 평균 검증 정확도 : ', np.mean(cv_accuracy))\n",
    "#정확도가 1.0인것은 학습데이터로 학습을 하고 학습데이터로 검증을 했을때 나올 수 있는 결과 \n",
    "#그냥 kfoldf를 사용하면 정확도가 왔다갔다 함 <- 문제 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Straitified K Fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    50\n",
       "1    50\n",
       "0    50\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df = pd.DataFrame(data = iris.data, columns = iris.feature_names)\n",
    "iris_df['label'] = iris.target\n",
    "#iris_df에 label이라는 컬럼을 추가 \n",
    "iris_df['label'].value_counts()\n",
    "#value_count() : 각 label의 개수를 도출 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ## 교차검증 : 1\n",
      "학습 레이블 데이터 분포 : \n",
      " 2    50\n",
      "1    50\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포 : \n",
      " 0    50\n",
      "Name: label, dtype: int64\n",
      " ## 교차검증 : 2\n",
      "학습 레이블 데이터 분포 : \n",
      " 2    50\n",
      "0    50\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포 : \n",
      " 1    50\n",
      "Name: label, dtype: int64\n",
      " ## 교차검증 : 3\n",
      "학습 레이블 데이터 분포 : \n",
      " 1    50\n",
      "0    50\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포 : \n",
      " 2    50\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits = 3 )\n",
    "\n",
    "n_iter= 0\n",
    "for train_index, test_index in kfold.split(iris_df):\n",
    "    #3개로 지정을 했으니 한개의 fold는 전체 데이터셋/3 \n",
    "    n_iter += 1\n",
    "    label_train = iris_df['label'].iloc[train_index]\n",
    "    label_test = iris_df['label'].iloc[test_index]\n",
    "    print(' ## 교차검증 : {0}'.format(n_iter))\n",
    "    print('학습 레이블 데이터 분포 : \\n', label_train.value_counts())\n",
    "    print('검증 레이블 데이터 분포 : \\n', label_test.value_counts())\n",
    "    #학습에 100, 검증에 50\n",
    "    #결과를 보면 검증을 진행하면서 fold가 변하는 것을 볼 수 있음 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차검증 : 1\n",
      "학습데이터 분포 \n",
      " 2    33\n",
      "1    33\n",
      "0    33\n",
      "Name: label, dtype: int64\n",
      "검증데이터 분포 \n",
      " 2    17\n",
      "1    17\n",
      "0    17\n",
      "Name: label, dtype: int64\n",
      "교차검증 : 2\n",
      "학습데이터 분포 \n",
      " 2    33\n",
      "1    33\n",
      "0    33\n",
      "Name: label, dtype: int64\n",
      "검증데이터 분포 \n",
      " 2    17\n",
      "1    17\n",
      "0    17\n",
      "Name: label, dtype: int64\n",
      "교차검증 : 3\n",
      "학습데이터 분포 \n",
      " 2    34\n",
      "1    34\n",
      "0    34\n",
      "Name: label, dtype: int64\n",
      "검증데이터 분포 \n",
      " 2    16\n",
      "1    16\n",
      "0    16\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "#StratifiedKFold : 클래스의 비율에 맞게 fold를 나누어라 <- 중요 \n",
    "\n",
    "skf = StratifiedKFold(n_splits = 3)\n",
    "n_iter = 0\n",
    "\n",
    "for train_index, test_index in skf.split(iris_df,iris_df['label']):\n",
    "    n_iter += 1 \n",
    "    label_train = iris_df['label'].iloc[train_index]\n",
    "    label_test = iris_df['label'].iloc[test_index]\n",
    "    print('교차검증 : {0}'.format(n_iter))\n",
    "    print('학습데이터 분포 \\n', label_train.value_counts())\n",
    "    print('검증데이터 분포 \\n', label_test.value_counts())\n",
    "    #label의 비율에 맞게 교차검증을 각각 나눔\n",
    "    #비율에 맞게 나눠주기때문에 약간의 개수가 다를 수 있음\n",
    "    #현재 데이터의 비율이 1:1:1임으로 잘분배가 된것을 확인을 할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    50\n",
       "1    50\n",
       "0    50\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df = pd.DataFrame(data = iris.data, columns = iris.feature_names)\n",
    "iris_df['label'] = iris.target\n",
    "#iris_df에 label이라는 컬럼을 추가 \n",
    "iris_df['label'].value_counts()\n",
    "#value_count() : 각 label의 개수를 도출 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#1 교차검증 정확도 : 0.9804, 학습데이터 크기 : 99, 검증데이터 크기 : 51\n",
      "#1 검증 세트 인덱스 : [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  50\n",
      "  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116]\n",
      "\n",
      "#2 교차검증 정확도 : 0.9216, 학습데이터 크기 : 99, 검증데이터 크기 : 51\n",
      "#2 검증 세트 인덱스 : [ 17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  67\n",
      "  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83 117 118\n",
      " 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133]\n",
      "\n",
      "#3 교차검증 정확도 : 0.9792, 학습데이터 크기 : 102, 검증데이터 크기 : 48\n",
      "#3 검증 세트 인덱스 : [ 34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  84  85\n",
      "  86  87  88  89  90  91  92  93  94  95  96  97  98  99 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "\n",
      "## 교차 검증 저확도 :  [0.9804 0.9216 0.9792]\n",
      "\n",
      "## 평균 검증 정확도 :  0.9604\n"
     ]
    }
   ],
   "source": [
    "#StratifiedKFold : 클래스의 비율에 맞게 fold를 나누어라 <- 중요 \n",
    "\n",
    "dt_clf = DecisionTreeClassifier(random_state = 200) # random_state를 바꾸니 정확도가 개선 \n",
    "skfold= StratifiedKFold(n_splits = 3)\n",
    "n_iter = 0\n",
    "cv_accuracy1  = []\n",
    "\n",
    "for train_index, test_index in skfold.split(features,label):\n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    #각각 지정 \n",
    "    y_train, y_test = label[train_index], label[test_index]\n",
    "    #학습 , 예측 \n",
    "    dt_clf.fit(X_train, y_train)\n",
    "    pred = dt_clf.predict(X_test)\n",
    "\n",
    "    n_iter += 1\n",
    "    #한번씩 반복될때마다 1씩 추가 \n",
    "    #반복 시 마다 정확도 측정 \n",
    "    accuracy = np.round(accuracy_score(y_test,pred),4)\n",
    "    train_size = X_train.shape[0]\n",
    "    #[[]]로 되어있으며 첫번째에 있기때문에 [0]으로 해야함\n",
    "    test_size = X_test.shape[0]\n",
    "    print('\\n#{0} 교차검증 정확도 : {1}, 학습데이터 크기 : {2}, 검증데이터 크기 : {3}'.format(n_iter, accuracy, train_size, test_size))\n",
    "    #위와 같은 방법으로 다양한 결과데이터들을 한번에 출력이 가능 \n",
    "    print('#{0} 검증 세트 인덱스 : {1}'.format(n_iter, test_index))\n",
    "    cv_accuracy1.append(accuracy)\n",
    "    \n",
    "#개별 iteration별 정확도를 합하여 평균을 계산하고 정확도를 도출 \n",
    "print('\\n## 교차 검증 저확도 : ', np.round(cv_accuracy1,4))\n",
    "print('\\n## 평균 검증 정확도 : ', np.mean(cv_accuracy1))\n",
    "\n",
    "#각 라벨의 비율별로 분리된것을 검증 세트 인덱스를 통해 확인가능 \n",
    "#교차 검증별 정확도가 꾸준하게 상승,하락을 하기때문에 StratifiedKFold가 안정적인것을 확인할 수 있다 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross_Val_Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증별 정확도 :  [0.9804 0.9216 0.9792]\n",
      "평균 검증 정확도 :  0.9604\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "dt_clf = DecisionTreeClassifier(random_state = 200)\n",
    "\n",
    "data = iris_data.data\n",
    "label = iris_data.target\n",
    "\n",
    "#성능 지표는 accuracy, 교차검증 세트는 3개\n",
    "scores = cross_val_score(dt_clf, data, label, scoring = 'accuracy', cv = 3)\n",
    "print('교차 검증별 정확도 : ', np.round(scores, 4))\n",
    "print('평균 검증 정확도 : ', np.round(np.mean(scores), 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearchCV(이거 좋네)\n",
    "##### 하이퍼파라미터의 모든 조합을 섞어가면서 조합을 찾음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target,\n",
    "                                                   test_size = 0.2, random_state = 12 )\n",
    "dtree = DecisionTreeClassifier()\n",
    "\n",
    "parameters = {'max_depth':[1,2,3],'min_samples_split':[2,3]}\n",
    "#parameters에 개별 파라미터를 조정 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Moon/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 2}</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>5</td>\n",
       "      <td>0.585366</td>\n",
       "      <td>0.658537</td>\n",
       "      <td>0.657895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 3}</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>5</td>\n",
       "      <td>0.585366</td>\n",
       "      <td>0.658537</td>\n",
       "      <td>0.657895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 2}</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>0.921053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 3}</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>0.921053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 2}</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>2</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.975610</td>\n",
       "      <td>0.921053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 3}</td>\n",
       "      <td>0.941667</td>\n",
       "      <td>1</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.975610</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     params  mean_test_score  rank_test_score  \\\n",
       "0  {'max_depth': 1, 'min_samples_split': 2}         0.633333                5   \n",
       "1  {'max_depth': 1, 'min_samples_split': 3}         0.633333                5   \n",
       "2  {'max_depth': 2, 'min_samples_split': 2}         0.925000                3   \n",
       "3  {'max_depth': 2, 'min_samples_split': 3}         0.925000                3   \n",
       "4  {'max_depth': 3, 'min_samples_split': 2}         0.933333                2   \n",
       "5  {'max_depth': 3, 'min_samples_split': 3}         0.941667                1   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  \n",
       "0           0.585366           0.658537           0.657895  \n",
       "1           0.585366           0.658537           0.657895  \n",
       "2           0.902439           0.951220           0.921053  \n",
       "3           0.902439           0.951220           0.921053  \n",
       "4           0.902439           0.975610           0.921053  \n",
       "5           0.902439           0.975610           0.947368  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_dtree = GridSearchCV(dtree, param_grid = parameters, cv = 3, refit = True)\n",
    "#패키지의 파라미터를 보고 시프명 shift + tap \n",
    "#교차검증을 3개로 하고 위에서 조정한 parameter를 넣어주고 최적의 파라미터를 찾기 위해 조정 \n",
    "#refit : 최고의 성능을 내는 하이퍼파라미터를 찾고 찾은 파라미터를 통해 학습을 다시 한번 돌려주는 기능 \n",
    "\n",
    "#train데이터로 학습 \n",
    "grid_dtree.fit(X_train,y_train)\n",
    "\n",
    "scores_df = pd.DataFrame(grid_dtree.cv_results_)\n",
    "#cv_results_ 값이 df형태로 scores_df로 저장 \n",
    "scores_df[['params', 'mean_test_score', 'rank_test_score', \\\n",
    "           'split0_test_score', 'split1_test_score', 'split2_test_score']]\n",
    "#이걸 사용해서 RF나 XG를 Light GBM을 사용할때 사용 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적의 파라미터 :  {'max_depth': 3, 'min_samples_split': 3}\n",
      "최고 정확도 : 0.941667\n"
     ]
    }
   ],
   "source": [
    "print('최적의 파라미터 : ', grid_dtree.best_params_)\n",
    "print('최고 정확도 : {0:4f}'.format(grid_dtree.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터 정확도 : 0.933333\n"
     ]
    }
   ],
   "source": [
    "e = grid_dtree.best_estimator_\n",
    "\n",
    "pred = e.predict(X_test)\n",
    "print('테스트 데이터 정확도 : {0:4f}'.format(accuracy_score(y_test,pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
